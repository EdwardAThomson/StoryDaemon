"""Compile command - merge all scenes into a manuscript."""
import re
from pathlib import Path
from typing import List, Optional, Tuple
from datetime import datetime


def parse_scene_range(range_str: str) -> List[int]:
    """Parse scene range string into list of scene numbers.
    
    Args:
        range_str: Range string like "1-10" or "5,7,9" or "1-5,8,10-12"
        
    Returns:
        List of scene numbers
    """
    scene_numbers = []
    
    for part in range_str.split(','):
        part = part.strip()
        if '-' in part:
            # Range
            start, end = part.split('-')
            scene_numbers.extend(range(int(start), int(end) + 1))
        else:
            # Single number
            scene_numbers.append(int(part))
    
    return sorted(set(scene_numbers))


def get_scene_files(scenes_dir: Path, scene_range: Optional[str] = None) -> List[Path]:
    """Get list of scene files to compile.
    
    Args:
        scenes_dir: Path to scenes directory
        scene_range: Optional range string to filter scenes
        
    Returns:
        List of scene file paths
    """
    all_scenes = sorted(scenes_dir.glob("scene_*.md"))
    
    if not scene_range:
        return all_scenes
    
    # Parse range
    scene_numbers = parse_scene_range(scene_range)
    
    # Filter scenes
    filtered = []
    for scene_file in all_scenes:
        # Extract number from filename
        match = re.search(r'scene_(\d+)\.md', scene_file.name)
        if match:
            scene_num = int(match.group(1))
            if scene_num in scene_numbers:
                filtered.append(scene_file)
    
    return filtered


def read_scene_content(scene_file: Path, strip_header: bool = False) -> str:
    """Read scene content from file.
    
    Args:
        scene_file: Path to scene file
        strip_header: If True, remove the scene header (title, metadata, separator)
        
    Returns:
        Scene content as string
    """
    try:
        with open(scene_file, 'r', encoding='utf-8') as f:
            content = f.read().strip()
        
        if strip_header:
            # Scene files have format:
            # # Title line
            # *Scene ID: ...*
            # *Tick: ...*
            #
            # ---
            #
            # [prose content]
            #
            # Strip everything up to and including the first "---" separator
            separator_match = re.search(r'^---\s*$', content, re.MULTILINE)
            if separator_match:
                content = content[separator_match.end():].strip()
        
        return content
    except Exception as e:
        return f"[Error reading scene: {e}]"


def count_words(text: str) -> int:
    """Count words in text.
    
    Args:
        text: Text to count words in
        
    Returns:
        Word count
    """
    return len(text.split())


def get_project_metadata(project_dir: Path) -> dict:
    """Get project metadata for manuscript header.
    
    Args:
        project_dir: Path to project directory
        
    Returns:
        Metadata dictionary
    """
    import json
    
    state_file = project_dir / "state.json"
    metadata = {
        'novel_name': 'Unknown',
        'created_at': datetime.now().strftime('%Y-%m-%d'),
    }
    
    if state_file.exists():
        try:
            with open(state_file, 'r') as f:
                state = json.load(f)
                metadata['novel_name'] = state.get('novel_name', 'Unknown')
                metadata['created_at'] = state.get('created_at', metadata['created_at'])
        except Exception:
            pass
    
    return metadata


def count_entities(project_dir: Path) -> Tuple[int, int]:
    """Count characters and locations.
    
    Args:
        project_dir: Path to project directory
        
    Returns:
        Tuple of (character_count, location_count)
    """
    memory_dir = project_dir / "memory"
    
    char_count = len(list((memory_dir / "characters").glob("*.json"))) if (memory_dir / "characters").exists() else 0
    loc_count = len(list((memory_dir / "locations").glob("*.json"))) if (memory_dir / "locations").exists() else 0
    
    return char_count, loc_count


def compile_to_markdown(project_dir: Path, scene_files: List[Path], 
                       include_metadata: bool = True) -> str:
    """Compile scenes to markdown format.
    
    Args:
        project_dir: Path to project directory
        scene_files: List of scene files to compile
        include_metadata: Include metadata appendix
        
    Returns:
        Compiled manuscript as string
    """
    metadata = get_project_metadata(project_dir)
    
    # Build manuscript
    lines = []
    
    # Header
    lines.append(f"# {metadata['novel_name']}")
    lines.append("")
    lines.append("**Author:** Generated by StoryDaemon")
    lines.append(f"**Scenes:** {len(scene_files)}")
    lines.append(f"**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    lines.append("")
    lines.append("---")
    lines.append("")
    
    # Scenes
    total_words = 0
    for i, scene_file in enumerate(scene_files, 1):
        content = read_scene_content(scene_file)
        words = count_words(content)
        total_words += words
        
        lines.append(f"## Scene {i}")
        lines.append("")
        lines.append(content)
        lines.append("")
        lines.append("---")
        lines.append("")
    
    # Metadata appendix
    if include_metadata:
        char_count, loc_count = count_entities(project_dir)
        
        lines.append("## Appendix")
        lines.append("")
        lines.append(f"**Characters:** {char_count}")
        lines.append(f"**Locations:** {loc_count}")
        lines.append(f"**Total Words:** {total_words:,}")
        lines.append("")
    
    return "\n".join(lines)


def compile_to_prose(project_dir: Path, scene_files: List[Path],
                     include_metadata: bool = False) -> str:
    """Compile scenes to prose-only format (no headers, just concatenated text).
    
    Args:
        project_dir: Path to project directory
        scene_files: List of scene files to compile
        include_metadata: Include word count at end (default False for clean prose)
        
    Returns:
        Compiled prose as string
    """
    lines = []
    total_words = 0
    
    for i, scene_file in enumerate(scene_files):
        content = read_scene_content(scene_file, strip_header=True)
        words = count_words(content)
        total_words += words
        
        lines.append(content)
        
        # Add scene break (blank line) between scenes, but not after last
        if i < len(scene_files) - 1:
            lines.append("")
            lines.append("* * *")  # Scene break marker
            lines.append("")
    
    if include_metadata:
        lines.append("")
        lines.append("---")
        lines.append(f"*Total words: {total_words:,}*")
    
    return "\n".join(lines)


def compile_to_html(project_dir: Path, scene_files: List[Path],
                   include_metadata: bool = True) -> str:
    """Compile scenes to HTML format.
    
    Args:
        project_dir: Path to project directory
        scene_files: List of scene files to compile
        include_metadata: Include metadata appendix
        
    Returns:
        Compiled manuscript as HTML string
    """
    metadata = get_project_metadata(project_dir)
    
    # Simple HTML template
    html_parts = []
    html_parts.append("<!DOCTYPE html>")
    html_parts.append("<html>")
    html_parts.append("<head>")
    html_parts.append(f"<title>{metadata['novel_name']}</title>")
    html_parts.append("<meta charset='utf-8'>")
    html_parts.append("<style>")
    html_parts.append("""
        body {
            font-family: Georgia, serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            line-height: 1.6;
        }
        h1 {
            text-align: center;
            margin-bottom: 10px;
        }
        .metadata {
            text-align: center;
            color: #666;
            margin-bottom: 40px;
        }
        .scene {
            margin-bottom: 40px;
            page-break-after: always;
        }
        .scene h2 {
            border-bottom: 2px solid #333;
            padding-bottom: 10px;
        }
        .scene-content {
            text-align: justify;
        }
        .appendix {
            margin-top: 60px;
            padding-top: 20px;
            border-top: 2px solid #333;
        }
    """)
    html_parts.append("</style>")
    html_parts.append("</head>")
    html_parts.append("<body>")
    
    # Header
    html_parts.append(f"<h1>{metadata['novel_name']}</h1>")
    html_parts.append("<div class='metadata'>")
    html_parts.append("<p><strong>Generated by StoryDaemon</strong></p>")
    html_parts.append(f"<p>Scenes: {len(scene_files)} | Generated: {datetime.now().strftime('%Y-%m-%d')}</p>")
    html_parts.append("</div>")
    
    # Scenes
    total_words = 0
    for i, scene_file in enumerate(scene_files, 1):
        content = read_scene_content(scene_file)
        words = count_words(content)
        total_words += words
        
        # Convert markdown-style paragraphs to HTML
        paragraphs = content.split('\n\n')
        html_content = ''.join(f"<p>{p.strip()}</p>" for p in paragraphs if p.strip())
        
        html_parts.append("<div class='scene'>")
        html_parts.append(f"<h2>Scene {i}</h2>")
        html_parts.append("<div class='scene-content'>")
        html_parts.append(html_content)
        html_parts.append("</div>")
        html_parts.append("</div>")
    
    # Appendix
    if include_metadata:
        char_count, loc_count = count_entities(project_dir)
        
        html_parts.append("<div class='appendix'>")
        html_parts.append("<h2>Appendix</h2>")
        html_parts.append(f"<p><strong>Characters:</strong> {char_count}</p>")
        html_parts.append(f"<p><strong>Locations:</strong> {loc_count}</p>")
        html_parts.append(f"<p><strong>Total Words:</strong> {total_words:,}</p>")
        html_parts.append("</div>")
    
    html_parts.append("</body>")
    html_parts.append("</html>")
    
    return "\n".join(html_parts)


def compile_manuscript(project_dir: Path, output: Path, format: str = "markdown",
                      include_metadata: bool = True, scene_range: Optional[str] = None) -> bool:
    """Compile all scenes into a single manuscript.
    
    Args:
        project_dir: Path to project directory
        output: Output file path
        format: Output format (markdown, html, prose, pdf)
        include_metadata: Include metadata appendix
        scene_range: Optional scene range filter
        
    Returns:
        True if successful, False otherwise
    """
    scenes_dir = project_dir / "scenes"
    
    if not scenes_dir.exists():
        print("‚ùå No scenes directory found")
        return False
    
    # Get scene files
    scene_files = get_scene_files(scenes_dir, scene_range)
    
    if not scene_files:
        print("‚ùå No scenes found to compile")
        return False
    
    print(f"üìù Compiling {len(scene_files)} scenes...")
    
    # Compile based on format
    if format == "markdown":
        content = compile_to_markdown(project_dir, scene_files, include_metadata)
    elif format == "html":
        content = compile_to_html(project_dir, scene_files, include_metadata)
    elif format == "prose":
        content = compile_to_prose(project_dir, scene_files, include_metadata)
    elif format == "pdf":
        print("‚ùå PDF format requires pandoc (not yet implemented)")
        return False
    else:
        print(f"‚ùå Unknown format: {format}. Supported: markdown, html, prose")
        return False
    
    # Write output
    try:
        with open(output, 'w', encoding='utf-8') as f:
            f.write(content)
        
        # Calculate stats
        word_count = count_words(content)
        
        print(f"‚úÖ Compiled {len(scene_files)} scenes to {output}")
        print(f"üìä Total words: {word_count:,}")
        return True
        
    except Exception as e:
        print(f"‚ùå Error writing output: {e}")
        return False
